## Dynamic Hierarchical Empirical Bayes: A Predictive Model Applied to Online Advertising



データ構造上の階層的な情報を利用した動的階層経験ベイズモデルを提案。



### 背景

リスティング広告：CPC課金

キャンペーンの下にAdGroup

階層的= キャンペーン単位でターゲティングすると、その下のAdGroupやキーワードにも適用される。（ターゲティングは地理・ユーザ情報を指定する。）



RPC Prediction (revenue per click)

入札単位=あるAdGroup内でのキーワード＋そのマッチタイプ（部分一致or完全一致or…）で1つの入札単位とする。

入札単位ではスパースすぎる

・CTR10%→ x-sparsity

・CVR2%→ y-sparsity



### 手法

#### 2レベル階層ベイズ

クリック数から収益を求める線形回帰の係数 $\beta$ を求めたい。

事前分布は正規分布として、尤度関数を使って事後分布を求める→式(1)

入札単位ごとに事後分布の平均を推定値とする。



伝統的な階層ベイズでは、階層構造はドメイン知識によって事前に決められる。

ここでは、あるキーワードが別のAdGroup内で設定されている場合、キーワードの下にAdGroupがあるべきで、データドリブンな状況である。



#### 階層減損

ある決められた損失関数に従って分割していくtreeモデルのように、階層を作っていく。

ある親ノードの子ノードは同じ事前分布を共有する。→parent information

損失関数(3)によって、ノード内の情報損失と親ノードとの間の損失からなる。



#### 動的階層経験ベイズ

親ノードが同じなら、事前分布も同じ。→ 階層構造を通して情報が伝わる。

完全な同時事後分布は、事前に決めた階層構造から生成され、シミュレーションで推測値が求められるが、計算量が大変。

なので、経験ベイズを使って、上から下に階層構造を作っていく。



式(6)の$\alpha$と$\gamma$の重みが、それぞれOLS推定値と事前分布の分散に対して反比例な件について、

・事前分布の分散が大きいときは、$\beta$の推定値に対するノイズが大きくなるので、影響を小さくしたい。

・同様に、サンプルデータがばらついてるときにはあまり重みを載せない。

損失関数を定義したので、式(7)に従って、どの属性で分割するべきかを決める。

再帰的に分割していくので、ルートノードのパラメータだけは事前に必要。

（ルートノードの事後分布がその子ノードの事前分布になるから）

経験ベイズでは、サンプルの平均を事前分布の平均、サンプルの重み付き分散を事前分布の分散として扱うことができる。

分割を停止するときの条件が式(8)



最後に入札単位層を付け加える。分割していったら、それぞれの内部に入札単位に対応するデータが入ってるので。



推測するときは、ルートから下に向かって(4)と(5)を繰り返し適用していく。



**Algorithm 1**

式(7)で損失関数(6)を最小化する属性$l$によって分割して子ノードを作る。

停止条件(8)を満たさない場合、子ノードについて分割を繰り返す。



### シミュレーション実験

6つのモデルで実験

(1) WA: 入札単位について、過去のクリック数を重みとしてRPCの重み付き平均をとったものを推測値とする。

(2) RLR: 上位階層の属性をすべて使った正規化線形回帰

(3) 2HB: 4.2で説明した2階層のモデル（ルート-入札単位）

(4) 3HB: 3階層を事前に決めておいて、Rstanで事後分布をサンプリングし、最下層の平均を推測値とする。

(5) FHEB: 階層を固定で。推測は提案手法と同じ。

(6) DHEB: 提案手法



シミュレーション用データ生成法(1)〜(7)

(1) 入札単位は100個。階層は4つで、それぞれ10から20個の属性。期間は6ヶ月。

(2) 潜在的な階層としては、A-B-C-D-入札単位

(3) 最上位の事前分布は、平均$\mu_0$で分散$\sigma_0^2$

(4) 中間層のノードについては、親ノードの分布$N(\mu_p, \sigma_p^2)$から平均$\mu_c$を生成する。子ノードの分散は$\sigma_0^2$で固定。

(5) 最下層の入札単位階層では、平均を(4)と同様に生成して、この入札単位のRPCとする。長さ$n$のクリックのリスト$X$を生成し、収益$Y$を$Y=RPC \times X + \epsilon$で決定する。

(6) x-sparsityは $n$ に反比例して決まる。y-sparsityはランダムに収益を0とする個数$s$によって決まる。

(7) $n$と$s$の組み合わせを9ペア生成し、各ペアについて10通りのデータセットを生成した。



2ヶ月のデータを使って翌日を予測する、というのをスライドさせながら30日分試した。

評価指標は式(9)



3HBでは、ルート-A-入札単位。FHEBでは、真の階層を使う。

WAをベースラインとして、他の5モデルを比較。

(9)のAVG-MSEの減少割合で評価する。

いろんな$n$と$s$の組み合わせの結果が図3の上段。FHEBが最高で、次がDHEB。x-sparsityとy-sparsityが増加するとFHEBとDHEBの優位さが目立つ。

時間計算量では、3HBが一番大きい。（図3の下段）



### 実験結果

実データで。属性は表1にあるような。階層以外に使ったのは曜日とGeoだけ。

階層構造の事前生成は難しい。3HBでは、ルート-キャンペーン-入札単位。FHEBでは、ルート-検索エンジン-…。←Geoだけ使ってない。1カテゴリーしかない属性だから。

図4の左がWAとのAVG-MSEの比較。DHEBがトップ。

真ん中が時間計算量。やっぱり3HBだけ突出。



図5は、複数のテスト期間で訓練した階層構造。頻繁に変わることはない。

システムとしては3つのモジュールに分けて、

(1) データ収集: 入札単位の属性、日次のクリック数と過去の収益を収集

(2) モデル学習: DHEBを学習して階層構築

(3) 予測

このうち(3)だけオンライン。→図6

(2)は一番時間がかかるが、階層構造は頻繁に変わらないのでたまにオフラインで学習するだけで大丈夫。

図4の右がモデル構築の頻度を表していて、4日ごとに構築するのがベスト。



### 結論

DHEBを提案。損失関数に従って階層構造を動的に構築する。経験ベイズのアプローチで推測する。shrinkage-basedな推測でスパースなデータに対応。